ğŸ“š RAG-ChatBot ğŸ¤–
A Retrieval-Augmented Generation (RAG) Chatbot using LangChain, Groq (LLM), and FAISS to answer questions based on your uploaded documents.
It supports PDFs, DOCX, TXT, CSV, and JSON files â€” and lets you chat with your data!

ğŸš€ Features
âœ… Upload documents and index them into a vector database.
âœ… Query your documents in natural language.
âœ… Uses Groq LLM via LangChain for fast, high-quality responses.
âœ… FAISS for vector search.
âœ… Streamlit frontend with a chat interface.
âœ… Cites content excerpts from the documents.
âœ… Supports multiple document formats.

ğŸ› ï¸ Tech Stack
Python ğŸ
Streamlit â€” frontend
FastAPI â€” backend
LangChain â€” orchestration
FAISS â€” vector store
Groq â€” LLM provider

1ï¸âƒ£ Clone the repo
bash
Copy code
git clone https://github.com/<your-username>/RAG-ChatBot.git
cd RAG-ChatBot


2ï¸âƒ£ Install dependencies
Itâ€™s recommended to use a virtual environment:

bash
Copy code
python -m venv venv
source venv/bin/activate      # On Linux/Mac
venv\Scripts\activate         # On Windows

pip install -r requirements.txt


3ï¸âƒ£ Set up your .env
Create a .env file and add your keys:

env
Copy code
GROQ_API_KEY=your_groq_api_key
API_URL_CHAT=http://127.0.0.1:8000/query
API_URL_PROCESS=http://127.0.0.1:8000/process-documents


4ï¸âƒ£ Start the backend (FastAPI)
bash
Copy code
uvicorn main:app --reload


5ï¸âƒ£ Start the frontend (Streamlit)
bash
Copy code
streamlit run frontend.py
Then visit http://localhost:8501 in your browser.

ğŸ§¹ Notes
If you want to ignore runtime folders like uploaded_files/ and faiss_index/, add them to .gitignore.

You can customize the prompt, response format, and models in src/retrieval_chain.py.

ğŸ™Œ Credits
Built with â¤ï¸ using LangChain, FAISS, and Groq.

Developed by Anjana Suresh â€” feel free to contribute!
